{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bde4f8ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.0\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import unicodedata\n",
    "import re\n",
    "import json\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import acquire"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5eb576b",
   "metadata": {},
   "source": [
    "# 1. Define a function named basic_clean. It should take in a string and apply some basic text cleaning to it.\n",
    "- ### Lowercase everything\n",
    "- ### Normalize unicode characters\n",
    "- ### Replace anything that is not a letter, number, whitespace or a single quote."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4002712",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_string = 'In the broadest dêfinition, a time series is any data set where the values are measured at different points in time. Many time series are uniformly spaced $$$ at a specific frequency, for example, hourly weather measurements, daily counts of web site visits, or monthly sales totals. Time series can also be irregularly spaced and sporadic, for example, timestamped data in a computer system’s event log or a history of 911 emergency calls. Pandas time series tools apply equally well to either type of time series.'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3836bc58",
   "metadata": {},
   "source": [
    "Convert all to lowercase:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab8eed43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'in the broadest dêfinition, a time series is any data set where the values are measured at different points in time. many time series are uniformly spaced $$$ at a specific frequency, for example, hourly weather measurements, daily counts of web site visits, or monthly sales totals. time series can also be irregularly spaced and sporadic, for example, timestamped data in a computer system’s event log or a history of 911 emergency calls. pandas time series tools apply equally well to either type of time series.'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string = test_string.lower()\n",
    "string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd22df7a",
   "metadata": {},
   "source": [
    "Remove Non-Ascii Characters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9754e6ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In the broadest definition, a time series is any data set where the values are measured at different points in time. Many time series are uniformly spaced $$$ at a specific frequency, for example, hourly weather measurements, daily counts of web site visits, or monthly sales totals. Time series can also be irregularly spaced and sporadic, for example, timestamped data in a computer systems event log or a history of 911 emergency calls. Pandas time series tools apply equally well to either type of time series.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string = unicodedata.normalize('NFKD', test_string).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744cd3d2",
   "metadata": {},
   "source": [
    "Remove special characters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca7143cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'n the broadest dfinition a time series is any data set where the values are measured at different points in time any time series are uniformly spaced  at a specific frequency for example hourly weather measurements daily counts of web site visits or monthly sales totals ime series can also be irregularly spaced and sporadic for example timestamped data in a computer systems event log or a history of 911 emergency calls andas time series tools apply equally well to either type of time series'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string = re.sub(r\"[^a-z0-9'\\s]\", '', test_string)\n",
    "string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b40c0bac",
   "metadata": {},
   "source": [
    "##### Test function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3bcb8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from prepare import basic_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cabaf672",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'in the broadest definition a time series is any data set where the values are measured at different points in time many time series are uniformly spaced  at a specific frequency for example hourly weather measurements daily counts of web site visits or monthly sales totals time series can also be irregularly spaced and sporadic for example timestamped data in a computer systems event log or a history of 911 emergency calls pandas time series tools apply equally well to either type of time series'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string = basic_clean(test_string)\n",
    "string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f5d622f",
   "metadata": {},
   "source": [
    "# 2. Define a function named tokenize. It should take in a string and tokenize all the words in the string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fba9a8bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In the broadest dêfinition , a time series is any data set where the values are measured at different points in time. Many time series are uniformly spaced $ $ $ at a specific frequency , for example , hourly weather measurements , daily counts of web site visits , or monthly sales totals. Time series can also be irregularly spaced and sporadic , for example , timestamped data in a computer system ’ s event log or a history of 911 emergency calls. Pandas time series tools apply equally well to either type of time series .'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = ToktokTokenizer()\n",
    "\n",
    "string = tokenizer.tokenize(test_string, return_str=True)\n",
    "string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b46b1df",
   "metadata": {},
   "source": [
    "##### Test Function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8492d5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from prepare import tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cf75460a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In the broadest dêfinition , a time series is any data set where the values are measured at different points in time. Many time series are uniformly spaced $ $ $ at a specific frequency , for example , hourly weather measurements , daily counts of web site visits , or monthly sales totals. Time series can also be irregularly spaced and sporadic , for example , timestamped data in a computer system ’ s event log or a history of 911 emergency calls. Pandas time series tools apply equally well to either type of time series .'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string = tokenize(test_string)\n",
    "string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f660be",
   "metadata": {},
   "source": [
    "# 3. Define a function named stem. It should accept some text and return the text after applying stemming to all the words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a9477c74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['in', 'the', 'broadest', 'dêfinition,', 'a']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps = nltk.porter.PorterStemmer()\n",
    "stems = [ps.stem(word) for word in test_string.split()]\n",
    "stems[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c0bce2f",
   "metadata": {},
   "source": [
    "##### Test Function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "07dc48c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from prepare import stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "41c7db79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'in th'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stems = stem(test_string)\n",
    "stems[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b567dbc",
   "metadata": {},
   "source": [
    "# 4. Define a function named lemmatize. It should accept some text and return the text after applying lemmatization to each word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e4fb11de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['In', 'the', 'broadest', 'dêfinition,', 'a']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wnl = nltk.stem.WordNetLemmatizer()\n",
    "lemmas = [wnl.lemmatize(word) for word in test_string.split()]\n",
    "lemmas[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52450aea",
   "metadata": {},
   "source": [
    "##### Test Function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "77fa4f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from prepare import lemmatize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d7d4aada",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In th'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmas = lemmatize(test_string)\n",
    "lemmas[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1848ad61",
   "metadata": {},
   "source": [
    "# 5. Define a function named remove_stopwords. It should accept some text and return the text after removing all the stopwords.\n",
    "-This function should define two optional parameters, extra_words and exclude_words. These parameters should define any additional stop words to include, and any words that we don't want to remove."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "977ef2f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 26 stopwords\n",
      "-----\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'In broadest dêfinition, time series set values are measured different points time. Many time series are uniformly spaced $$$ specific frequency, example, hourly weather measurements, daily counts web site visits, monthly sales totals. Time series also irregularly spaced sporadic, example, timestamped computer system’s event log history 911 emergency calls. Pandas time series tools apply equally well either type time series.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopword_list = stopwords.words('english')\n",
    "# Remove stopwords to remove\n",
    "exclude_words = ['are']\n",
    "for word in exclude_words:\n",
    "    stopword_list.remove(word)\n",
    "# Adds additional stopwords\n",
    "extra_words = ['data']\n",
    "for word in extra_words:\n",
    "    stopword_list.append(word)\n",
    "words = test_string.split()\n",
    "filtered_words = [w for w in words if w not in stopword_list]\n",
    "print('Removed {} stopwords'.format(len(words) - len(filtered_words)))\n",
    "\n",
    "stopwordless_string = ' '.join(filtered_words)\n",
    "print('-----')\n",
    "stopwordless_string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b945765",
   "metadata": {},
   "source": [
    "##### Test Function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7def8a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from prepare import remove_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4a4b72c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 27 stopwords\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'In the broadest dêfinition, time series set the values measured different points time. Many time series uniformly spaced $$$ specific frequency, example, weather measurements, daily counts web site visits, monthly sales totals. Time series also irregularly spaced sporadic, example, timestamped computer system’s event log history 911 emergency calls. Pandas time series tools apply equally well either type time series.'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exclude_words = ['the']\n",
    "extra_words = ['data','hourly']\n",
    "\n",
    "string = remove_stopwords(test_string,extra_words,exclude_words)\n",
    "string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03934564",
   "metadata": {},
   "source": [
    "##### Altogether:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5389b7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from prepare import full_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a0f5eb01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 28 stopwords\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'the broadest definition time series set the value measured different point time many time series uniformly spaced specific frequency example weather measurement daily count web site visit monthly sale total time series also irregularly spaced sporadic example timestamped computer system event log history 911 emergency call panda time series tool apply equally well either type time series'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_string = full_clean(test_string, extra_words, exclude_words)\n",
    "cleaned_string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fff39b5",
   "metadata": {},
   "source": [
    "# 6. Use your data from the acquire to produce a dataframe of the news articles. Name the dataframe news_df. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "06e51205",
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = acquire.get_news_articles()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7102a4bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rupee hits 80 per US dollar for the first time...</td>\n",
       "      <td>The Indian rupee touched 80 per US dollar for ...</td>\n",
       "      <td>Business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ED arrests ex-Mumbai Police chief Sanjay Pande...</td>\n",
       "      <td>The Enforcement Directorate (ED) on Tuesday ar...</td>\n",
       "      <td>Business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gautam Adani overtakes Bill Gates to become wo...</td>\n",
       "      <td>Gautam Adani has overtaken Bill Gates to becom...</td>\n",
       "      <td>Business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Who are now the world's 10 richest people as A...</td>\n",
       "      <td>Gautam Adani has overtaken Bill Gates to becom...</td>\n",
       "      <td>Business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>List of items exempt from GST when sold loose ...</td>\n",
       "      <td>Amid criticism over pre-packaged and pre-label...</td>\n",
       "      <td>Business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>I salute Sushmita Sen for living life on her o...</td>\n",
       "      <td>Filmmaker Mahesh Bhatt defended Sushmita Sen a...</td>\n",
       "      <td>Entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Joe Russo arrives in Mumbai ahead of 'The Gray...</td>\n",
       "      <td>Filmmaker Joe Russo has arrived in Mumbai ahea...</td>\n",
       "      <td>Entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Told them to get lost: Mallika Sherawat on bei...</td>\n",
       "      <td>Actress Mallika Sherawat revealed she was offe...</td>\n",
       "      <td>Entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Jackie Chan opened doors for me in H'wood, he'...</td>\n",
       "      <td>Talking about Jackie Chan, Mallika Sherawat sa...</td>\n",
       "      <td>Entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Yuvraj Singh, Harbhajan approached for 'Jhalak...</td>\n",
       "      <td>Ex-Indian cricketers Yuvraj Singh, Harbhajan S...</td>\n",
       "      <td>Entertainment</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                title  \\\n",
       "0   Rupee hits 80 per US dollar for the first time...   \n",
       "1   ED arrests ex-Mumbai Police chief Sanjay Pande...   \n",
       "2   Gautam Adani overtakes Bill Gates to become wo...   \n",
       "3   Who are now the world's 10 richest people as A...   \n",
       "4   List of items exempt from GST when sold loose ...   \n",
       "..                                                ...   \n",
       "95  I salute Sushmita Sen for living life on her o...   \n",
       "96  Joe Russo arrives in Mumbai ahead of 'The Gray...   \n",
       "97  Told them to get lost: Mallika Sherawat on bei...   \n",
       "98  Jackie Chan opened doors for me in H'wood, he'...   \n",
       "99  Yuvraj Singh, Harbhajan approached for 'Jhalak...   \n",
       "\n",
       "                                              content       category  \n",
       "0   The Indian rupee touched 80 per US dollar for ...       Business  \n",
       "1   The Enforcement Directorate (ED) on Tuesday ar...       Business  \n",
       "2   Gautam Adani has overtaken Bill Gates to becom...       Business  \n",
       "3   Gautam Adani has overtaken Bill Gates to becom...       Business  \n",
       "4   Amid criticism over pre-packaged and pre-label...       Business  \n",
       "..                                                ...            ...  \n",
       "95  Filmmaker Mahesh Bhatt defended Sushmita Sen a...  Entertainment  \n",
       "96  Filmmaker Joe Russo has arrived in Mumbai ahea...  Entertainment  \n",
       "97  Actress Mallika Sherawat revealed she was offe...  Entertainment  \n",
       "98  Talking about Jackie Chan, Mallika Sherawat sa...  Entertainment  \n",
       "99  Ex-Indian cricketers Yuvraj Singh, Harbhajan S...  Entertainment  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df = pd.DataFrame(articles)\n",
    "news_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a263fb1",
   "metadata": {},
   "source": [
    "# 7. Make another dataframe for the Codeup blog posts. Name the dataframe codeup_df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2139f99f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "blogs = acquire.acquire_codeup_blog()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "eeb80295",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Published</th>\n",
       "      <th>Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Project Quest Info Session: IT Jumpstart on Ma...</td>\n",
       "      <td>May 11, 2022</td>\n",
       "      <td>Join our grant partner Project Quest as they d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Codeup Dallas: How to Succeed at a Coding Boot...</td>\n",
       "      <td>May 23, 2022</td>\n",
       "      <td>This event is the perfect opportunity for peop...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What Jobs Can You Get After a Coding Bootcamp?...</td>\n",
       "      <td>Jul 14, 2022</td>\n",
       "      <td>Have you been considering a career in Cloud Ad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5 Reasons To Attend Our New Cloud Administrati...</td>\n",
       "      <td>May 17, 2022</td>\n",
       "      <td>Come Work In The Cloud\\nWhen your Monday rolls...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>In-Person Workshop: Learn to Code – Python on ...</td>\n",
       "      <td>Jun 20, 2022</td>\n",
       "      <td>According to LinkedIn, the “#1 Most Promising ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title     Published  \\\n",
       "0  Project Quest Info Session: IT Jumpstart on Ma...  May 11, 2022   \n",
       "1  Codeup Dallas: How to Succeed at a Coding Boot...  May 23, 2022   \n",
       "2  What Jobs Can You Get After a Coding Bootcamp?...  Jul 14, 2022   \n",
       "3  5 Reasons To Attend Our New Cloud Administrati...  May 17, 2022   \n",
       "4  In-Person Workshop: Learn to Code – Python on ...  Jun 20, 2022   \n",
       "\n",
       "                                             Content  \n",
       "0  Join our grant partner Project Quest as they d...  \n",
       "1  This event is the perfect opportunity for peop...  \n",
       "2  Have you been considering a career in Cloud Ad...  \n",
       "3  Come Work In The Cloud\\nWhen your Monday rolls...  \n",
       "4  According to LinkedIn, the “#1 Most Promising ...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "codeup_df = pd.DataFrame(blogs)\n",
    "codeup_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e133d7",
   "metadata": {},
   "source": [
    "# 8. For each dataframe, produce the following columns:\n",
    "- title to hold the title\n",
    "- original to hold the original article/post content\n",
    "- clean to hold the normalized and tokenized original with the stopwords removed.\n",
    "- stemmed to hold the stemmed version of the cleaned data.\n",
    "- lemmatized to hold the lemmatized version of the cleaned data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ad4f6f",
   "metadata": {},
   "source": [
    "### News:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "8c890ade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 20 stopwords\n",
      "Removed 19 stopwords\n",
      "Removed 19 stopwords\n",
      "Removed 16 stopwords\n",
      "Removed 15 stopwords\n",
      "Removed 15 stopwords\n",
      "Removed 20 stopwords\n",
      "Removed 17 stopwords\n",
      "Removed 18 stopwords\n",
      "Removed 17 stopwords\n",
      "Removed 16 stopwords\n",
      "Removed 16 stopwords\n",
      "Removed 21 stopwords\n",
      "Removed 20 stopwords\n",
      "Removed 19 stopwords\n",
      "Removed 27 stopwords\n",
      "Removed 25 stopwords\n",
      "Removed 25 stopwords\n",
      "Removed 22 stopwords\n",
      "Removed 18 stopwords\n",
      "Removed 20 stopwords\n",
      "Removed 24 stopwords\n",
      "Removed 21 stopwords\n",
      "Removed 22 stopwords\n",
      "Removed 15 stopwords\n",
      "Removed 14 stopwords\n",
      "Removed 14 stopwords\n",
      "Removed 19 stopwords\n",
      "Removed 18 stopwords\n",
      "Removed 18 stopwords\n",
      "Removed 25 stopwords\n",
      "Removed 24 stopwords\n",
      "Removed 24 stopwords\n",
      "Removed 22 stopwords\n",
      "Removed 20 stopwords\n",
      "Removed 21 stopwords\n",
      "Removed 22 stopwords\n",
      "Removed 21 stopwords\n",
      "Removed 21 stopwords\n",
      "Removed 23 stopwords\n",
      "Removed 21 stopwords\n",
      "Removed 21 stopwords\n",
      "Removed 22 stopwords\n",
      "Removed 20 stopwords\n",
      "Removed 21 stopwords\n",
      "Removed 20 stopwords\n",
      "Removed 20 stopwords\n",
      "Removed 20 stopwords\n",
      "Removed 21 stopwords\n",
      "Removed 20 stopwords\n",
      "Removed 20 stopwords\n",
      "Removed 22 stopwords\n",
      "Removed 22 stopwords\n",
      "Removed 22 stopwords\n",
      "Removed 22 stopwords\n",
      "Removed 22 stopwords\n",
      "Removed 22 stopwords\n",
      "Removed 16 stopwords\n",
      "Removed 16 stopwords\n",
      "Removed 16 stopwords\n",
      "Removed 22 stopwords\n",
      "Removed 22 stopwords\n",
      "Removed 22 stopwords\n",
      "Removed 21 stopwords\n",
      "Removed 19 stopwords\n",
      "Removed 19 stopwords\n",
      "Removed 20 stopwords\n",
      "Removed 17 stopwords\n",
      "Removed 18 stopwords\n",
      "Removed 19 stopwords\n",
      "Removed 18 stopwords\n",
      "Removed 18 stopwords\n",
      "Removed 20 stopwords\n",
      "Removed 20 stopwords\n",
      "Removed 20 stopwords\n",
      "Removed 31 stopwords\n",
      "Removed 30 stopwords\n",
      "Removed 31 stopwords\n",
      "Removed 26 stopwords\n",
      "Removed 24 stopwords\n",
      "Removed 25 stopwords\n",
      "Removed 20 stopwords\n",
      "Removed 19 stopwords\n",
      "Removed 20 stopwords\n",
      "Removed 18 stopwords\n",
      "Removed 16 stopwords\n",
      "Removed 18 stopwords\n",
      "Removed 23 stopwords\n",
      "Removed 20 stopwords\n",
      "Removed 21 stopwords\n",
      "Removed 15 stopwords\n",
      "Removed 13 stopwords\n",
      "Removed 15 stopwords\n",
      "Removed 22 stopwords\n",
      "Removed 19 stopwords\n",
      "Removed 22 stopwords\n",
      "Removed 24 stopwords\n",
      "Removed 21 stopwords\n",
      "Removed 23 stopwords\n",
      "Removed 20 stopwords\n",
      "Removed 20 stopwords\n",
      "Removed 20 stopwords\n",
      "Removed 15 stopwords\n",
      "Removed 15 stopwords\n",
      "Removed 15 stopwords\n",
      "Removed 21 stopwords\n",
      "Removed 19 stopwords\n",
      "Removed 20 stopwords\n",
      "Removed 21 stopwords\n",
      "Removed 19 stopwords\n",
      "Removed 20 stopwords\n",
      "Removed 22 stopwords\n",
      "Removed 22 stopwords\n",
      "Removed 22 stopwords\n",
      "Removed 22 stopwords\n",
      "Removed 20 stopwords\n",
      "Removed 21 stopwords\n",
      "Removed 24 stopwords\n",
      "Removed 18 stopwords\n",
      "Removed 20 stopwords\n",
      "Removed 28 stopwords\n",
      "Removed 27 stopwords\n",
      "Removed 27 stopwords\n",
      "Removed 28 stopwords\n",
      "Removed 27 stopwords\n",
      "Removed 27 stopwords\n",
      "Removed 20 stopwords\n",
      "Removed 19 stopwords\n",
      "Removed 19 stopwords\n",
      "Removed 29 stopwords\n",
      "Removed 26 stopwords\n",
      "Removed 27 stopwords\n",
      "Removed 21 stopwords\n",
      "Removed 20 stopwords\n",
      "Removed 20 stopwords\n",
      "Removed 29 stopwords\n",
      "Removed 25 stopwords\n",
      "Removed 27 stopwords\n",
      "Removed 25 stopwords\n",
      "Removed 24 stopwords\n",
      "Removed 25 stopwords\n",
      "Removed 30 stopwords\n",
      "Removed 27 stopwords\n",
      "Removed 28 stopwords\n",
      "Removed 22 stopwords\n",
      "Removed 22 stopwords\n",
      "Removed 23 stopwords\n",
      "Removed 22 stopwords\n",
      "Removed 20 stopwords\n",
      "Removed 20 stopwords\n",
      "Removed 25 stopwords\n",
      "Removed 24 stopwords\n",
      "Removed 24 stopwords\n",
      "Removed 7 stopwords\n",
      "Removed 6 stopwords\n",
      "Removed 6 stopwords\n",
      "Removed 17 stopwords\n",
      "Removed 16 stopwords\n",
      "Removed 16 stopwords\n",
      "Removed 20 stopwords\n",
      "Removed 17 stopwords\n",
      "Removed 18 stopwords\n",
      "Removed 19 stopwords\n",
      "Removed 19 stopwords\n",
      "Removed 19 stopwords\n",
      "Removed 29 stopwords\n",
      "Removed 27 stopwords\n",
      "Removed 29 stopwords\n",
      "Removed 24 stopwords\n",
      "Removed 22 stopwords\n",
      "Removed 23 stopwords\n",
      "Removed 26 stopwords\n",
      "Removed 23 stopwords\n",
      "Removed 23 stopwords\n",
      "Removed 15 stopwords\n",
      "Removed 14 stopwords\n",
      "Removed 14 stopwords\n",
      "Removed 22 stopwords\n",
      "Removed 18 stopwords\n",
      "Removed 20 stopwords\n",
      "Removed 27 stopwords\n",
      "Removed 25 stopwords\n",
      "Removed 25 stopwords\n",
      "Removed 26 stopwords\n",
      "Removed 26 stopwords\n",
      "Removed 26 stopwords\n",
      "Removed 24 stopwords\n",
      "Removed 21 stopwords\n",
      "Removed 22 stopwords\n",
      "Removed 30 stopwords\n",
      "Removed 27 stopwords\n",
      "Removed 29 stopwords\n",
      "Removed 27 stopwords\n",
      "Removed 24 stopwords\n",
      "Removed 25 stopwords\n",
      "Removed 19 stopwords\n",
      "Removed 18 stopwords\n",
      "Removed 18 stopwords\n",
      "Removed 21 stopwords\n",
      "Removed 20 stopwords\n",
      "Removed 20 stopwords\n",
      "Removed 20 stopwords\n",
      "Removed 18 stopwords\n",
      "Removed 20 stopwords\n",
      "Removed 26 stopwords\n",
      "Removed 21 stopwords\n",
      "Removed 24 stopwords\n",
      "Removed 29 stopwords\n",
      "Removed 27 stopwords\n",
      "Removed 27 stopwords\n",
      "Removed 14 stopwords\n",
      "Removed 13 stopwords\n",
      "Removed 13 stopwords\n",
      "Removed 28 stopwords\n",
      "Removed 26 stopwords\n",
      "Removed 28 stopwords\n",
      "Removed 24 stopwords\n",
      "Removed 23 stopwords\n",
      "Removed 24 stopwords\n",
      "Removed 22 stopwords\n",
      "Removed 20 stopwords\n",
      "Removed 21 stopwords\n",
      "Removed 21 stopwords\n",
      "Removed 19 stopwords\n",
      "Removed 19 stopwords\n",
      "Removed 27 stopwords\n",
      "Removed 25 stopwords\n",
      "Removed 26 stopwords\n",
      "Removed 29 stopwords\n",
      "Removed 28 stopwords\n",
      "Removed 28 stopwords\n",
      "Removed 22 stopwords\n",
      "Removed 21 stopwords\n",
      "Removed 21 stopwords\n",
      "Removed 27 stopwords\n",
      "Removed 22 stopwords\n",
      "Removed 26 stopwords\n",
      "Removed 22 stopwords\n",
      "Removed 21 stopwords\n",
      "Removed 21 stopwords\n",
      "Removed 27 stopwords\n",
      "Removed 24 stopwords\n",
      "Removed 24 stopwords\n",
      "Removed 29 stopwords\n",
      "Removed 26 stopwords\n",
      "Removed 26 stopwords\n",
      "Removed 31 stopwords\n",
      "Removed 28 stopwords\n",
      "Removed 28 stopwords\n",
      "Removed 25 stopwords\n",
      "Removed 24 stopwords\n",
      "Removed 24 stopwords\n",
      "Removed 29 stopwords\n",
      "Removed 27 stopwords\n",
      "Removed 29 stopwords\n",
      "Removed 26 stopwords\n",
      "Removed 24 stopwords\n",
      "Removed 25 stopwords\n",
      "Removed 27 stopwords\n",
      "Removed 27 stopwords\n",
      "Removed 27 stopwords\n",
      "Removed 29 stopwords\n",
      "Removed 26 stopwords\n",
      "Removed 27 stopwords\n",
      "Removed 25 stopwords\n",
      "Removed 23 stopwords\n",
      "Removed 25 stopwords\n",
      "Removed 29 stopwords\n",
      "Removed 25 stopwords\n",
      "Removed 28 stopwords\n",
      "Removed 28 stopwords\n",
      "Removed 23 stopwords\n",
      "Removed 26 stopwords\n",
      "Removed 21 stopwords\n",
      "Removed 17 stopwords\n",
      "Removed 20 stopwords\n",
      "Removed 31 stopwords\n",
      "Removed 28 stopwords\n",
      "Removed 30 stopwords\n",
      "Removed 27 stopwords\n",
      "Removed 23 stopwords\n",
      "Removed 25 stopwords\n",
      "Removed 28 stopwords\n",
      "Removed 23 stopwords\n",
      "Removed 26 stopwords\n",
      "Removed 30 stopwords\n",
      "Removed 29 stopwords\n",
      "Removed 29 stopwords\n",
      "Removed 24 stopwords\n",
      "Removed 21 stopwords\n",
      "Removed 22 stopwords\n",
      "Removed 31 stopwords\n",
      "Removed 27 stopwords\n",
      "Removed 28 stopwords\n",
      "Removed 28 stopwords\n",
      "Removed 28 stopwords\n",
      "Removed 28 stopwords\n",
      "Removed 21 stopwords\n",
      "Removed 20 stopwords\n",
      "Removed 20 stopwords\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>clean</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rupee hits 80 per US dollar for the first time...</td>\n",
       "      <td>The Indian rupee touched 80 per US dollar for ...</td>\n",
       "      <td>indian rupee touched 80 per us dollar first ti...</td>\n",
       "      <td>indian rupe touch 80 per us dollar first time ...</td>\n",
       "      <td>indian rupee touched 80 per u dollar first tim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ED arrests ex-Mumbai Police chief Sanjay Pande...</td>\n",
       "      <td>The Enforcement Directorate (ED) on Tuesday ar...</td>\n",
       "      <td>enforcement directorate ed tuesday arrested fo...</td>\n",
       "      <td>enforc director ed tuesday arrest former mumba...</td>\n",
       "      <td>enforcement directorate ed tuesday arrested fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gautam Adani overtakes Bill Gates to become wo...</td>\n",
       "      <td>Gautam Adani has overtaken Bill Gates to becom...</td>\n",
       "      <td>gautam adani overtaken bill gates become world...</td>\n",
       "      <td>gautam adani ha overtaken bill gate becom worl...</td>\n",
       "      <td>gautam adani ha overtaken bill gate become wor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Who are now the world's 10 richest people as A...</td>\n",
       "      <td>Gautam Adani has overtaken Bill Gates to becom...</td>\n",
       "      <td>gautam adani overtaken bill gates become world...</td>\n",
       "      <td>gautam adani ha overtaken bill gate becom worl...</td>\n",
       "      <td>gautam adani ha overtaken bill gate become wor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>List of items exempt from GST when sold loose ...</td>\n",
       "      <td>Amid criticism over pre-packaged and pre-label...</td>\n",
       "      <td>amid criticism prepackaged prelabelled food it...</td>\n",
       "      <td>amid critic prepackag prelabel food item get c...</td>\n",
       "      <td>amid criticism prepackaged prelabelled food it...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>I salute Sushmita Sen for living life on her o...</td>\n",
       "      <td>Filmmaker Mahesh Bhatt defended Sushmita Sen a...</td>\n",
       "      <td>filmmaker mahesh bhatt defended sushmita sen t...</td>\n",
       "      <td>filmmak mahesh bhatt defend sushmita sen wa tr...</td>\n",
       "      <td>filmmaker mahesh bhatt defended sushmita sen w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Joe Russo arrives in Mumbai ahead of 'The Gray...</td>\n",
       "      <td>Filmmaker Joe Russo has arrived in Mumbai ahea...</td>\n",
       "      <td>filmmaker joe russo arrived mumbai ahead premi...</td>\n",
       "      <td>filmmak joe russo ha arriv mumbai ahead premie...</td>\n",
       "      <td>filmmaker joe russo ha arrived mumbai ahead pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Told them to get lost: Mallika Sherawat on bei...</td>\n",
       "      <td>Actress Mallika Sherawat revealed she was offe...</td>\n",
       "      <td>actress mallika sherawat revealed offered tesh...</td>\n",
       "      <td>actress mallika sherawat reveal wa offer teshe...</td>\n",
       "      <td>actress mallika sherawat revealed wa offered t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Jackie Chan opened doors for me in H'wood, he'...</td>\n",
       "      <td>Talking about Jackie Chan, Mallika Sherawat sa...</td>\n",
       "      <td>talking jackie chan mallika sherawat said jack...</td>\n",
       "      <td>talk jacki chan mallika sherawat said jacki ch...</td>\n",
       "      <td>talking jackie chan mallika sherawat said jack...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Yuvraj Singh, Harbhajan approached for 'Jhalak...</td>\n",
       "      <td>Ex-Indian cricketers Yuvraj Singh, Harbhajan S...</td>\n",
       "      <td>exindian cricketers yuvraj singh harbhajan sin...</td>\n",
       "      <td>exindian cricket yuvraj singh harbhajan singh ...</td>\n",
       "      <td>exindian cricketer yuvraj singh harbhajan sing...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                title  \\\n",
       "0   Rupee hits 80 per US dollar for the first time...   \n",
       "1   ED arrests ex-Mumbai Police chief Sanjay Pande...   \n",
       "2   Gautam Adani overtakes Bill Gates to become wo...   \n",
       "3   Who are now the world's 10 richest people as A...   \n",
       "4   List of items exempt from GST when sold loose ...   \n",
       "..                                                ...   \n",
       "95  I salute Sushmita Sen for living life on her o...   \n",
       "96  Joe Russo arrives in Mumbai ahead of 'The Gray...   \n",
       "97  Told them to get lost: Mallika Sherawat on bei...   \n",
       "98  Jackie Chan opened doors for me in H'wood, he'...   \n",
       "99  Yuvraj Singh, Harbhajan approached for 'Jhalak...   \n",
       "\n",
       "                                              content  \\\n",
       "0   The Indian rupee touched 80 per US dollar for ...   \n",
       "1   The Enforcement Directorate (ED) on Tuesday ar...   \n",
       "2   Gautam Adani has overtaken Bill Gates to becom...   \n",
       "3   Gautam Adani has overtaken Bill Gates to becom...   \n",
       "4   Amid criticism over pre-packaged and pre-label...   \n",
       "..                                                ...   \n",
       "95  Filmmaker Mahesh Bhatt defended Sushmita Sen a...   \n",
       "96  Filmmaker Joe Russo has arrived in Mumbai ahea...   \n",
       "97  Actress Mallika Sherawat revealed she was offe...   \n",
       "98  Talking about Jackie Chan, Mallika Sherawat sa...   \n",
       "99  Ex-Indian cricketers Yuvraj Singh, Harbhajan S...   \n",
       "\n",
       "                                                clean  \\\n",
       "0   indian rupee touched 80 per us dollar first ti...   \n",
       "1   enforcement directorate ed tuesday arrested fo...   \n",
       "2   gautam adani overtaken bill gates become world...   \n",
       "3   gautam adani overtaken bill gates become world...   \n",
       "4   amid criticism prepackaged prelabelled food it...   \n",
       "..                                                ...   \n",
       "95  filmmaker mahesh bhatt defended sushmita sen t...   \n",
       "96  filmmaker joe russo arrived mumbai ahead premi...   \n",
       "97  actress mallika sherawat revealed offered tesh...   \n",
       "98  talking jackie chan mallika sherawat said jack...   \n",
       "99  exindian cricketers yuvraj singh harbhajan sin...   \n",
       "\n",
       "                                              stemmed  \\\n",
       "0   indian rupe touch 80 per us dollar first time ...   \n",
       "1   enforc director ed tuesday arrest former mumba...   \n",
       "2   gautam adani ha overtaken bill gate becom worl...   \n",
       "3   gautam adani ha overtaken bill gate becom worl...   \n",
       "4   amid critic prepackag prelabel food item get c...   \n",
       "..                                                ...   \n",
       "95  filmmak mahesh bhatt defend sushmita sen wa tr...   \n",
       "96  filmmak joe russo ha arriv mumbai ahead premie...   \n",
       "97  actress mallika sherawat reveal wa offer teshe...   \n",
       "98  talk jacki chan mallika sherawat said jacki ch...   \n",
       "99  exindian cricket yuvraj singh harbhajan singh ...   \n",
       "\n",
       "                                           lemmatized  \n",
       "0   indian rupee touched 80 per u dollar first tim...  \n",
       "1   enforcement directorate ed tuesday arrested fo...  \n",
       "2   gautam adani ha overtaken bill gate become wor...  \n",
       "3   gautam adani ha overtaken bill gate become wor...  \n",
       "4   amid criticism prepackaged prelabelled food it...  \n",
       "..                                                ...  \n",
       "95  filmmaker mahesh bhatt defended sushmita sen w...  \n",
       "96  filmmaker joe russo ha arrived mumbai ahead pr...  \n",
       "97  actress mallika sherawat revealed wa offered t...  \n",
       "98  talking jackie chan mallika sherawat said jack...  \n",
       "99  exindian cricketer yuvraj singh harbhajan sing...  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extra_words = []\n",
    "exclude_words = []\n",
    "df_holder = []\n",
    "\n",
    "for rows in news_df.index:\n",
    "    row = {}\n",
    "    title = news_df.iloc[rows][0]\n",
    "    content = news_df.iloc[rows][1]\n",
    "    \n",
    "    row['title'] = title\n",
    "    row['content'] = content\n",
    "    \n",
    "    news_df_cleaned = basic_clean(content)\n",
    "    news_df_cleaned = tokenize(news_df_cleaned)\n",
    "    news_df_cleaned = remove_stopwords(news_df_cleaned)\n",
    "    \n",
    "    row['clean'] = news_df_cleaned\n",
    "    \n",
    "    news_df_stem = full_clean(content,extra_words,exclude_words,stem_or_lemma = 'stem')\n",
    "    row['stemmed'] = news_df_stem\n",
    "\n",
    "    news_df_lemma = full_clean(content,extra_words,exclude_words)\n",
    "    row['lemmatized'] = news_df_lemma\n",
    "    \n",
    "    df_holder.append(row)\n",
    "pd.DataFrame(df_holder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ab56dc",
   "metadata": {},
   "source": [
    "### Blogs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "70e2ac2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 27 stopwords\n",
      "Removed 25 stopwords\n",
      "Removed 27 stopwords\n",
      "Removed 48 stopwords\n",
      "Removed 45 stopwords\n",
      "Removed 48 stopwords\n",
      "Removed 142 stopwords\n",
      "Removed 135 stopwords\n",
      "Removed 141 stopwords\n",
      "Removed 530 stopwords\n",
      "Removed 513 stopwords\n",
      "Removed 528 stopwords\n",
      "Removed 65 stopwords\n",
      "Removed 63 stopwords\n",
      "Removed 64 stopwords\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>clean</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Project Quest Info Session: IT Jumpstart on Ma...</td>\n",
       "      <td>Join our grant partner Project Quest as they d...</td>\n",
       "      <td>join grant partner project quest discuss lates...</td>\n",
       "      <td>join grant partner project quest discuss lates...</td>\n",
       "      <td>join grant partner project quest discus latest...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Codeup Dallas: How to Succeed at a Coding Boot...</td>\n",
       "      <td>This event is the perfect opportunity for peop...</td>\n",
       "      <td>event perfect opportunity people wondering exp...</td>\n",
       "      <td>thi event perfect opportun peopl wonder expect...</td>\n",
       "      <td>event perfect opportunity people wondering exp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What Jobs Can You Get After a Coding Bootcamp?...</td>\n",
       "      <td>Have you been considering a career in Cloud Ad...</td>\n",
       "      <td>considering career cloud administration idea j...</td>\n",
       "      <td>consid career cloud administr idea job titl po...</td>\n",
       "      <td>considering career cloud administration idea j...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5 Reasons To Attend Our New Cloud Administrati...</td>\n",
       "      <td>Come Work In The Cloud\\nWhen your Monday rolls...</td>\n",
       "      <td>come work cloud monday rolls around start get ...</td>\n",
       "      <td>come work cloud monday roll around start get s...</td>\n",
       "      <td>come work cloud monday roll around start get s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>In-Person Workshop: Learn to Code – Python on ...</td>\n",
       "      <td>According to LinkedIn, the “#1 Most Promising ...</td>\n",
       "      <td>according linkedin 1 promising job data scienc...</td>\n",
       "      <td>accord linkedin 1 promis job data scienc one m...</td>\n",
       "      <td>according linkedin 1 promising job data scienc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Project Quest Info Session: IT Jumpstart on Ma...   \n",
       "1  Codeup Dallas: How to Succeed at a Coding Boot...   \n",
       "2  What Jobs Can You Get After a Coding Bootcamp?...   \n",
       "3  5 Reasons To Attend Our New Cloud Administrati...   \n",
       "4  In-Person Workshop: Learn to Code – Python on ...   \n",
       "\n",
       "                                             content  \\\n",
       "0  Join our grant partner Project Quest as they d...   \n",
       "1  This event is the perfect opportunity for peop...   \n",
       "2  Have you been considering a career in Cloud Ad...   \n",
       "3  Come Work In The Cloud\\nWhen your Monday rolls...   \n",
       "4  According to LinkedIn, the “#1 Most Promising ...   \n",
       "\n",
       "                                               clean  \\\n",
       "0  join grant partner project quest discuss lates...   \n",
       "1  event perfect opportunity people wondering exp...   \n",
       "2  considering career cloud administration idea j...   \n",
       "3  come work cloud monday rolls around start get ...   \n",
       "4  according linkedin 1 promising job data scienc...   \n",
       "\n",
       "                                             stemmed  \\\n",
       "0  join grant partner project quest discuss lates...   \n",
       "1  thi event perfect opportun peopl wonder expect...   \n",
       "2  consid career cloud administr idea job titl po...   \n",
       "3  come work cloud monday roll around start get s...   \n",
       "4  accord linkedin 1 promis job data scienc one m...   \n",
       "\n",
       "                                          lemmatized  \n",
       "0  join grant partner project quest discus latest...  \n",
       "1  event perfect opportunity people wondering exp...  \n",
       "2  considering career cloud administration idea j...  \n",
       "3  come work cloud monday roll around start get s...  \n",
       "4  according linkedin 1 promising job data scienc...  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extra_words = []\n",
    "exclude_words = []\n",
    "df_holder = []\n",
    "\n",
    "for rows in codeup_df.index:\n",
    "    row = {}\n",
    "    title = codeup_df.iloc[rows][0]\n",
    "    content = codeup_df.iloc[rows][2]\n",
    "    \n",
    "    row['title'] = title\n",
    "    row['content'] = content\n",
    "    \n",
    "    news_df_cleaned = basic_clean(content)\n",
    "    news_df_cleaned = tokenize(news_df_cleaned)\n",
    "    news_df_cleaned = remove_stopwords(news_df_cleaned)\n",
    "    \n",
    "    row['clean'] = news_df_cleaned\n",
    "    \n",
    "    news_df_stem = full_clean(content,extra_words,exclude_words,stem_or_lemma = 'stem')\n",
    "    row['stemmed'] = news_df_stem\n",
    "\n",
    "    news_df_lemma = full_clean(content,extra_words,exclude_words)\n",
    "    row['lemmatized'] = news_df_lemma\n",
    "    \n",
    "    df_holder.append(row)\n",
    "pd.DataFrame(df_holder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "224325c2",
   "metadata": {},
   "source": [
    "# 9. Ask yourself:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c1b6506",
   "metadata": {},
   "source": [
    "### If your corpus is 493KB, would you prefer to use stemmed or lemmatized text?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df458124",
   "metadata": {},
   "source": [
    "- Lemmatized, almost definitely"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d3fa88",
   "metadata": {},
   "source": [
    "### If your corpus is 25MB, would you prefer to use stemmed or lemmatized text?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24689d24",
   "metadata": {},
   "source": [
    "- Probably lemmatize, maybe stem it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e53de0ed",
   "metadata": {},
   "source": [
    "### If your corpus is 200TB of text and you're charged by the megabyte for your hosted computational resources, would you prefer to use stemmed or lemmatized text?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13253c8f",
   "metadata": {},
   "source": [
    "- Almost certainly stem"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
